<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    
    <title>Spark学习之路（一） | DylanWen&#39;s  Blog</title>
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
        <meta name="keywords" content="Spark" />
    
    <meta name="description" content="研究生考试终于告一段落，但学习的脚步仍然不能停止。由于是往届生，在学校也没有住宿，校外住宿也不大方便，于是回来学习。为了尽快进入学习状态以及跟上实验室其他同学，张旭教授要求每周汇报一次学习进度，准备在自己的博客进行书写。 要求学习的内容及工具如下：  语言方面：   Java Python Scala    平台方面：   Spark Hive Processing      现阶段已经着手在电脑">
<meta name="keywords" content="Spark">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark学习之路（一）">
<meta property="og:url" content="http://wenshunjie.top/posts/programming/2019-04-04-Spark学习之路（一）.html">
<meta property="og:site_name" content="DylanWen&#39;s  Blog">
<meta property="og:description" content="研究生考试终于告一段落，但学习的脚步仍然不能停止。由于是往届生，在学校也没有住宿，校外住宿也不大方便，于是回来学习。为了尽快进入学习状态以及跟上实验室其他同学，张旭教授要求每周汇报一次学习进度，准备在自己的博客进行书写。 要求学习的内容及工具如下：  语言方面：   Java Python Scala    平台方面：   Spark Hive Processing      现阶段已经着手在电脑">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://dylanwen-1256745329.cos.ap-chengdu.myqcloud.com/pic_blog/spark1/spark-logo-trademark.png">
<meta property="og:updated_time" content="2019-04-07T15:26:03.789Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Spark学习之路（一）">
<meta name="twitter:description" content="研究生考试终于告一段落，但学习的脚步仍然不能停止。由于是往届生，在学校也没有住宿，校外住宿也不大方便，于是回来学习。为了尽快进入学习状态以及跟上实验室其他同学，张旭教授要求每周汇报一次学习进度，准备在自己的博客进行书写。 要求学习的内容及工具如下：  语言方面：   Java Python Scala    平台方面：   Spark Hive Processing      现阶段已经着手在电脑">
<meta name="twitter:image" content="https://dylanwen-1256745329.cos.ap-chengdu.myqcloud.com/pic_blog/spark1/spark-logo-trademark.png">
    

    

    
        <link rel="icon" href="/cake.ico" />
    

    <link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="/libs/titillium-web/styles.css">
    <link rel="stylesheet" href="/libs/source-code-pro/styles.css">

    <link rel="stylesheet" href="/css/style.css">

    <script src="/libs/jquery/2.0.3/jquery.min.js"></script>
    
    
        <link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">
    
    
    
        <script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?f8403e7c46b36682c7b150f2f5211325";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


</head>

<body>
    <div id="wrap">
        <header id="header">
    <div id="header-outer" class="outer">
        <div class="container">
            <div class="container-inner">
                <div id="header-title">
                    <h1 class="logo-wrap">
                        <a href="/" class="logo"></a>
                    </h1>
                    
                        <h2 class="subtitle-wrap">
                            <p class="subtitle">生活本可更精彩</p>
                        </h2>
                    
                </div>
                <div id="header-inner" class="nav-container">
                    <a id="main-nav-toggle" class="nav-icon fa fa-bars"></a>
                    <div class="nav-container-inner">
                        <ul id="main-nav">
                            
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/">主页</a>
                                </li>
                            
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/categories/life">过日子</a>
                                </li>
                            
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/categories/programming">滚键盘</a>
                                </li>
                            
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/categories/english">念洋文</a>
                                </li>
                            
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/about">关于</a>
                                </li>
                            
                        </ul>
                        <nav id="sub-nav">
                            <div id="search-form-wrap">

    <form class="search-form" method="GET" action="https://www.baidu.com/s?">
    <input name="wd" type="text" class="search-form-input" placeholder="搜索" />
</form>
<script>
(function ($) {
    $('.search-form').on('submit', function (e) {
        var keyword = $('.search-form-input[name="wd"]').val();
        window.location = 'https://www.baidu.com/s?wd=site:wenshunjie.top ' + keyword;
        return false;
    });
})(jQuery);
</script>

</div>
                        </nav>
                    </div>
                </div>
            </div>
        </div>
    </div>
</header>
        <div class="container">
            <div class="main-body container-inner">
                <div class="main-body-inner">
                    <section id="main">
                        <div class="main-body-header">
    <h1 class="header">
    
    <a class="page-title-link" href="/categories/programming/">滚键盘</a>
    </h1>
</div>
                        <div class="main-body-content">
                            <article id="post-Spark学习之路（一）" class="article article-single article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
        Spark学习之路（一）
        </h1>
    

            </header>
        
        
            <div class="article-meta">
                
    <div class="article-date">
        <a href="/posts/programming/2019-04-04-Spark学习之路（一）.html" class="article-date">
            <time datetime="2019-04-04T02:45:49.000Z" itemprop="datePublished">2019-04-04</time>
        </a>
    </div>

                
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/tags/Spark/">Spark</a>
    </div>

                阅读数量:<span id="/posts/programming/2019-04-04-Spark学习之路（一）.html" class="leancloud_visitors" data-flag-title="Spark学习之路（一）"></span>次
            </div>
        
        
        <div class="article-entry" itemprop="articleBody">
            <p>研究生考试终于告一段落，但学习的脚步仍然不能停止。由于是往届生，在学校也没有住宿，校外住宿也不大方便，于是回来学习。为了尽快进入学习状态以及跟上实验室其他同学，张旭教授要求每周汇报一次学习进度，准备在自己的博客进行书写。</p>
<p>要求学习的内容及工具如下：</p>
<ul>
<li><p>语言方面：</p>
<blockquote>
<ul>
<li>Java</li>
<li>Python</li>
<li>Scala</li>
</ul>
</blockquote>
</li>
<li><p>平台方面：</p>
<blockquote>
<ul>
<li>Spark</li>
<li>Hive</li>
<li>Processing</li>
</ul>
</blockquote>
</li>
</ul>
<p><img src="https://dylanwen-1256745329.cos.ap-chengdu.myqcloud.com/pic_blog/spark1/spark-logo-trademark.png" alt="Spark"></p>
<p>现阶段已经着手在电脑上使用<strong>VMware Workstation Pro 14</strong>来搭建环境，具体配置如下：</p>
<ul>
<li><p>硬件：</p>
<blockquote>
<ul>
<li>RAM:2GB</li>
<li>ROM:20GB</li>
<li>CORE:4</li>
<li>主机/从机:1master,1slave</li>
</ul>
</blockquote>
</li>
<li><p>软件：</p>
<blockquote>
<ul>
<li>Ubuntu:CentOS-7-x86_64-DVD-1810</li>
<li>Hadoop:3.2.0</li>
<li>Spark：2.2.3</li>
<li>Python:3.7.3</li>
<li>Anaconda:3.0</li>
<li>Jdk:1.8.0_201</li>
</ul>
</blockquote>
</li>
</ul>
<h2 id="为什么使用Spark来进行数据处理"><a href="#为什么使用Spark来进行数据处理" class="headerlink" title="为什么使用Spark来进行数据处理"></a>为什么使用Spark来进行数据处理</h2><h3 id="Spark简介"><a href="#Spark简介" class="headerlink" title="Spark简介"></a>Spark简介</h3><p><strong>Apache Spark</strong>是开放源码的集群运算框架，由加州大学伯克利分校的AMPLab开发。Spark是一个弹性的运算框架，适合进行Spark Streaming数据流处理、Spark SQL互动分析、MLlib机器学习等应用，因此Spark可作为一个用途广泛的大数据运算平台。Spark允许用户将数据加载到cluster集群的内存中存储，并多次重复运算，非常适合用于机器学习的算法。</p>
<p>Spark的核心是<strong>RDD(Resilient Distributed Dataset)弹性分布式数据集</strong>，是由AMPLab实验室所提出的的概念，属于一种分布式的内容。<br>Apache Spark是一种快速的集群计算技术，专为快速计算而设计。它基于Hadoop MapReduce，它扩展了MapReduce模型，以有效地将其用于更多类型的计算，包括交互式查询和流处理。 Spark的主要特性是它的内存中集群计算，提高了应用程序的处理速度。</p>
<p>Spark旨在涵盖各种工作负载，如批处理应用程序，迭代算法，交互式查询和流式处理。除了在相应系统中支持所有这些工作负载之外，它还减少了维护单独工具的管理负担。</p>
<h3 id="Spark和Hadoop的关系"><a href="#Spark和Hadoop的关系" class="headerlink" title="Spark和Hadoop的关系"></a>Spark和Hadoop的关系</h3><p>行业广泛使用Hadoop来分析他们的数据集。原因是Hadoop框架基于一个简单的编程模型（MapReduce），它支持可扩展，灵活，容错和成本有效的计算解决方案。这里，主要关注的是在处理大型数据集时在查询之间的等待时间和运行程序的等待时间方面保持速度。<br>Spark由Apache Software Foundation引入，用于加速Hadoop计算软件过程。<br>对于一个普遍的信念，Spark不是Hadoop的修改版本，并不是真的依赖于Hadoop，因为它有自己的集群管理。 Hadoop只是实现Spark的方法之一。<br>Spark以两种方式使用Hadoop - 一个是存储，另一个是处理。由于Spark具有自己的集群管理计算，因此它仅使用Hadoop进行存储。<br><img src="https://dylanwen-1256745329.cos.ap-chengdu.myqcloud.com/pic_blog/spark1/Hadoop%E5%92%8CSpark.jpg" alt="Hadoop和Spark"></p>
<h3 id="park的优势"><a href="#park的优势" class="headerlink" title="park的优势"></a>park的优势</h3><p>Apache Spark具有以下优势：</p>
<ol>
<li><p>速度</p>
<p>Spark有助于在Hadoop集群中运行应用程序，在内存中速度提高100倍，在磁盘上运行时提高10倍。这可以通过减少对磁盘的读/写操作的数量来实现。它将中间处理数据存储在存储器中。</p>
</li>
<li><p>支持多种语言</p>
<p>Spark在Java，Scala或Python中提供了内置的API。因此，您可以使用不同的语言编写应用程序。 Spark提供了80个高级操作员进行交互式查询。</p>
</li>
<li><p>高级分析</p>
<p>Spark不仅支持“Map”和“reduce”。它还支持SQL查询，流数据，机器学习（ML）和图算法。</p>
</li>
</ol>
<h3 id="Spark基于Hadoop"><a href="#Spark基于Hadoop" class="headerlink" title="Spark基于Hadoop"></a>Spark基于Hadoop</h3><p><img src="https://dylanwen-1256745329.cos.ap-chengdu.myqcloud.com/pic_blog/spark1/spark_built_on_hadoop.jpg" alt="Hadoop组件构建Spark的三种方式"></p>
<p>Spark部署有三种方式，如下所述:</p>
<ol>
<li><p>Standalone- Spark独立部署意味着Spark占据HDFS（Hadoop分布式文件系统）顶部的位置，并明确为HDFS分配空间。 这里，Spark和MapReduce将并行运行以覆盖集群上的所有spark作业。</p>
</li>
<li><p>Hadoop Yarn- Hadoop Yarn部署意味着，spark只需运行在Yarn上，无需任何预安装或根访问。 它有助于将Spark集成到Hadoop生态系统或Hadoop堆栈中。 它允许其他组件在堆栈顶部运行。</p>
</li>
<li><p>Spark in MapReduce (SIMR) - MapReduce中的Spark用于在独立部署之外启动spark job。 使用SIMR，用户可以启动Spark并使用其shell而无需任何管理访问。</p>
</li>
</ol>
<h3 id="Spark组件"><a href="#Spark组件" class="headerlink" title="Spark组件"></a>Spark组件</h3><p><img src="https://dylanwen-1256745329.cos.ap-chengdu.myqcloud.com/pic_blog/spark1/components_of_spark.jpg" alt="Spark组成部分"></p>
<ol>
<li><p>Apache Spark Core</p>
<p>Spark Core是spark平台的基础通用执行引擎，所有其他功能都是基于。它在外部存储系统中提供内存计算和引用数据集。</p>
</li>
<li><p>Spark SQL</p>
<p>Spark SQL是Spark Core之上的一个组件，它引入了一个称为SchemaRDD的新数据抽象，它为结构化和半结构化数据提供支持。</p>
</li>
<li><p>Spark Streaming</p>
<p>Spark Streaming利用Spark Core的快速调度功能来执行流式分析。它以小批量获取数据，并对这些小批量的数据执行RDD（弹性分布式数据集）转换。</p>
</li>
<li><p>MLlib (Machine Learning Library)</p>
<p>MLlib是Spark之上的分布式机器学习框架，因为基于分布式内存的Spark架构。根据基准，它是由MLlib开发人员针对交替最小二乘法（ALS）实现完成的。 Spark MLlib是基于Hadoop磁盘的Apache Mahout版本的9倍（在Mahout获得了Spark接口之前）。</p>
</li>
<li><p>GraphX<br>GraphX是Spark上的一个分布式图形处理框架。它提供了一个用于表达图形计算的API，可以通过使用Pregel抽象API为用户定义的图形建模。它还为此抽象提供了一个优化的运行时。</p>
</li>
</ol>
<h3 id="Python-Spark机器学习"><a href="#Python-Spark机器学习" class="headerlink" title="Python Spark机器学习"></a>Python Spark机器学习</h3><p>Python机器学习膜卷主要是Pandas、Scikit-learn，但是在大数据时代有大量的数据，必须具有分布式存储以及分布式计算才能够处理。有了Spark之后，使用Python开发Spark应用程序，可以使用HDFS分布式存储大量数据。还可以使用在多台计算机所建立的集群（例如：Spark stand alone、Hadoop YARN、Mesos）上来执行分布式计算。再加上Spark特有的内存运算，让执行速度大幅提升。</p>
<p>Spark机器学习主要有两个API：</p>
<ol>
<li><p>Spark MLlib:RDD-based 机器学习API：<br>Spark在一开始就提供了以RDD为基础的机器学习模块，优点是可以发挥in-memory与分布式运算，大幅提升需要迭代的机器学习模块的执行效率，功能强大，能完成Spark所有功能。</p>
</li>
<li><p>Spark ML pipeline:DataFrames-based 机器学习API:<br>DataFrame与Spark Pipeline机器学习API的设计由来如下：</p>
<blockquote>
<p>DataFrame : Spark受Pandas程序包启发所设计的数据处理架构。<br>Spark Pipeline : Spark受Scikit-learn程序包启发所设计的机器学习架构。</p>
</blockquote>
</li>
</ol>
<p><img src="https://dylanwen-1256745329.cos.ap-chengdu.myqcloud.com/pic_blog/spark1/%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E8%BD%AF%E4%BB%B6%E5%8C%85.jpg" alt="常用数据分析软件包"></p>
<h2 id="Linux虚拟机与Hadoop分布式平台搭建"><a href="#Linux虚拟机与Hadoop分布式平台搭建" class="headerlink" title="Linux虚拟机与Hadoop分布式平台搭建"></a>Linux虚拟机与Hadoop分布式平台搭建</h2><p>在毕设的时候采用的也是VMvare运行CentOS7的Linux虚拟机，这次采用Ubuntu的系统，开始觉得应该大同小异，并且以前配置过环境，会比较轻车熟路，但是实际上到Pyspark正常运行也花了两天时间，期间踩了无数的坑，为了以后更好的配置环境，现记录如下，并且汇总自己的踩坑记录。</p>
<h3 id="安装Ubuntu"><a href="#安装Ubuntu" class="headerlink" title="安装Ubuntu"></a>安装Ubuntu</h3><p>系统安装过程不难，需要注意到是Ubuntu输入法的设置以及设置共享剪贴板。</p>
<h4 id="输入法设置"><a href="#输入法设置" class="headerlink" title="输入法设置"></a>输入法设置</h4><p>由于安装的时候选择语言是汉语，但是大部分情况下输入命令和程序都是英文，必须自行切换输入法，这样极其不方便，所以最好把默认输入法改成英文并且把输入法切换方式改成我们Windows常用的方式。</p>
<p>在设置&gt;设备&gt;键盘中进行切换方式的设置。</p>
<h4 id="共享剪贴板设置"><a href="#共享剪贴板设置" class="headerlink" title="共享剪贴板设置"></a>共享剪贴板设置</h4><p>在VMvare软件中，自带有VMTools工具，可以将Windows和虚拟机共享剪贴板，挂载VMTools进行解压安装即可。</p>
<p>至于选择最佳下载服务器，这个我觉得不太必要设置。</p>
<h3 id="Hadoop分布式系统配置"><a href="#Hadoop分布式系统配置" class="headerlink" title="Hadoop分布式系统配置"></a>Hadoop分布式系统配置</h3><h4 id="安装JDK"><a href="#安装JDK" class="headerlink" title="安装JDK"></a>安装JDK</h4><p>Hadoop是使用Java开发的，所以必须先安装JDK。由于在安装Ubuntu的时候已经选择了安装开发环境，所以已经自动安装好了较高版本的Java，但是这也是影响我后面无法启动ResorceManager进程的一个原因（详见爬坑记录）。</p>
<p>所以我最终是采用Jdk:1.8.0_201：</p>
<p><strong>查询Java版本</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Java -version</span><br></pre></td></tr></table></figure>
<p><strong>查询Java安装路径</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">update-alternatives --display Java</span><br></pre></td></tr></table></figure>
<p>####SSH免密登陆</p>
<p>Hadoop是由多台服务器组成，再启动Hadoop系统时，NameNode必须与DataNode连接并且管理这些节点。系统会要求用户输入密码，为了系统顺利运行而不手动输入密码，通常采用SSH设置成无密码登陆。在安装系统的时候好像也已经存在了SSH和rsync，以防万一补充安装方法。</p>
<p><strong>安装SSH</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install ssh</span><br></pre></td></tr></table></figure>
<p><strong>安装rsync</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install rsync</span><br></pre></td></tr></table></figure>
<p><strong>主节点免密登陆</strong></p>
<p>在主节点的终端输入：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa</span><br></pre></td></tr></table></figure>
<p>然后一路回车默认安装位置，如果已经存在就覆盖。</p>
<p><strong>将key放到许可证文件并修改权限</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span><br><span class="line">chmod 600 authorized_keys</span><br><span class="line">chmod 700 .ssh</span><br></pre></td></tr></table></figure>
<p><strong>将authorized_keys发送到从节点data1</strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp authorized_keys hduser@data1:~/.ssh</span><br></pre></td></tr></table></figure></p>
<p>同样地也修改从节点处的权限。</p>
<p><strong>SSH访问</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh data1</span><br></pre></td></tr></table></figure>
<h4 id="下载安装Hadoop"><a href="#下载安装Hadoop" class="headerlink" title="下载安装Hadoop"></a>下载安装Hadoop</h4><p>两种方式我觉得都比较方便，一种是采用wget命令，进行远程下载，另一种是在Windows系统下载之后通过VMTools的共享文件夹的方式传输的Linux下进行解压安装。</p>
<p><strong>wget下载</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget http://archive.apache.org/dist/hadoop/common/hadoop-3.2.0/hadoop-3.2.0.tar.gz</span><br></pre></td></tr></table></figure>
<p><strong>解压缩Hadoop</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo tar -zxvf hadoop-3.2.0.tar.gz</span><br></pre></td></tr></table></figure>
<p><strong>移动Hadoop到/usr/local</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo mv hadoop-3.2.0 /usr/<span class="built_in">local</span>/hadoop</span><br></pre></td></tr></table></figure>
<h4 id="设置Hadoop环境变量"><a href="#设置Hadoop环境变量" class="headerlink" title="设置Hadoop环境变量"></a>设置Hadoop环境变量</h4><p>每个组件配置环境变量是最关键的一环，并且版本不同的Hadoop在环境变量的配置上也有细微的差别，由于我采用了最新的3.2.0的版本，踩了许多坑，详见爬坑记录，现附我已经配置成功的主、从机代码。</p>
<h5 id="主机"><a href="#主机" class="headerlink" title="主机"></a>主机</h5><p><strong>编辑~/.bashrc</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo gedit ~/.bashrc</span><br></pre></td></tr></table></figure>
<p>该文件是系统整体环境变量的核心，想要直接通过hadoop、java、scala等命令访问，就必须配置好这个文件，在文件末尾加入：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/lib/jvm/jdk1.8.0_201</span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/usr/<span class="built_in">local</span>/hadoop </span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/bin </span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/sbin </span><br><span class="line"><span class="built_in">export</span> HADOOP_MAPRED_HOME=<span class="variable">$HADOOP_HOME</span> </span><br><span class="line"><span class="built_in">export</span> HADOOP_COMMON_HOME=<span class="variable">$HADOOP_HOME</span> </span><br><span class="line"><span class="built_in">export</span> HADOOP_HDFS_HOME=<span class="variable">$HADOOP_HOME</span> </span><br><span class="line"><span class="built_in">export</span> YARN_HOME=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_COMMON_LIB_NATIVE_DIR=<span class="variable">$HADOOP_HOME</span>/lib/native </span><br><span class="line"><span class="built_in">export</span> HADOOP_OPTS=<span class="string">"-Djava.library.path=<span class="variable">$HADOOP_HOME</span>/lib"</span> </span><br><span class="line"><span class="built_in">export</span> JAVA_LIBRARY_PATH=<span class="variable">$HADOOP_HOME</span>/lib/native:<span class="variable">$JAVA_LIBRARY_PATH</span></span><br><span class="line"><span class="comment"># hadoop</span></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$&#123;JAVA_HOME&#125;</span>/bin:<span class="variable">$PATH</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_CLASSPATH=<span class="variable">$&#123;JAVA_HOME&#125;</span>/lib/tools.jar</span><br><span class="line"><span class="comment"># scala</span></span><br><span class="line"><span class="built_in">export</span> SCALA_HOME=/usr/<span class="built_in">local</span>/scala</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$&#123;SCALA_HOME&#125;</span>/bin:<span class="variable">$PATH</span></span><br><span class="line"><span class="comment"># spark</span></span><br><span class="line"><span class="built_in">export</span> SPARK_HOME=/usr/<span class="built_in">local</span>/spark</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$&#123;SPARK_HOME&#125;</span>/bin:<span class="variable">$PATH</span></span><br><span class="line"><span class="comment"># python</span></span><br><span class="line"><span class="built_in">export</span> PYTHONPATH=<span class="variable">$ANACONDA_PATH</span>/bin/python</span><br><span class="line"><span class="built_in">export</span> PYSPARK_PYTHON=<span class="variable">$ANACONDA_PATH</span>/bin/python</span><br><span class="line"><span class="comment"># anaconda</span></span><br><span class="line"><span class="built_in">export</span> PATH=/home/hduser/anaconda3/bin:<span class="variable">$PATH</span></span><br><span class="line"><span class="built_in">export</span> ANACONDA_PATH=/home/hduser/anaconda3</span><br><span class="line"><span class="built_in">export</span> PYSPARK_DRIVER_PYTHON=<span class="variable">$ANACONDA_PATH</span>/bin/ipython</span><br></pre></td></tr></table></figure>
<p>配置完成之后，从系统注销再登陆系统，设置可以立即生效，或者使用source是其生效，输入：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure>
<p><strong>Hadoop-env.sh</strong></p>
<p>打开文件的操作不再赘述，直接附上我的配置文件，在最后加上：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/lib/jvm/jdk1.8.0_201</span><br><span class="line"><span class="built_in">export</span> HADOOP_OPTS=<span class="string">"-Djava.library.path=<span class="variable">$HADOOP_HOME</span>/lib"</span> </span><br><span class="line"><span class="built_in">export</span> HDFS_NAMENODE_USER=hduser</span><br><span class="line"><span class="built_in">export</span> HDFS_DATANODE_USER=hduser</span><br><span class="line"><span class="built_in">export</span> HDFS_SECONDARYNAMENODE_USER=hduser</span><br></pre></td></tr></table></figure>
<p><strong>core-site.xml</strong></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://master:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/usr/local/hadoop/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>namenode上本地的hadoop临时文件夹<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p><strong>YARN-site.xml</strong></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services.mapreduce.shuffle.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.mapred.ShuffleHandler<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>master<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.address.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>data1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>data1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p><strong>mapred-site.xml</strong></p>
<p>首先复制模板文件：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo cp /usr/<span class="built_in">local</span>/hadoop/etc/hadoop/mapred-site.xml.template  /usr/<span class="built_in">local</span>/hadoop/etc/hadoop/mapred-site.xml</span><br></pre></td></tr></table></figure>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>vix.mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p><strong>hdfs-site.xml</strong></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/hadoop_data/hdfs/namenode<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.http.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>master:50070<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p><strong>创建并格式化HDFS目录</strong></p>
<p>创建文namenode数据存储目录：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir -p /usr/<span class="built_in">local</span>/hadoop/hadoop_data/hdfs/namenode</span><br></pre></td></tr></table></figure></p>
<p>设置Hadoop目录的所有者为hduser：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo chown hduser:hduser -R /usr/<span class="built_in">local</span>/hadoop</span><br></pre></td></tr></table></figure>
<p>格式化HDFS：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop namenode -format</span><br></pre></td></tr></table></figure>
        </div>
        <footer class="article-footer">
            



    <a data-url="http://wenshunjie.top/posts/programming/2019-04-04-Spark学习之路（一）.html" data-id="cju72ybld0006msr3ts7otjz4" class="article-share-link"><i class="fa fa-share"></i>分享到</a>
<script>
    (function ($) {
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

        </footer>
    </div>
</article>
<!-- 来必力City版安装代码 -->
<div id="lv-container" data-id="city" data-uid="MTAyMC8zMzEyMi85Njgx">
<script type="text/javascript">
   (function(d, s) {
       var j, e = d.getElementsByTagName(s)[0];

       if (typeof LivereTower === 'function') { return; }

       j = d.createElement(s);
       j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
       j.async = true;

       e.parentNode.insertBefore(j, e);
   })(document, 'script');
</script>
<noscript>为正常使用来必力评论功能请激活JavaScript</noscript>
</div>
<!-- City版安装代码已完成 -->


                        </div>
                    </section>
                    <aside id="sidebar">
    <a class="sidebar-toggle" title="Expand Sidebar"><i class="toggle icon"></i></a>
    <div class="sidebar-top">
        <p>关注我 :</p>
        <ul class="social-links">
            
                
                <li>
                    <a class="social-tooltip" title="github" href="https://github.com/DylanWhen/dylanwhen.github.io" target="_blank">
                        <i class="icon fa fa-github"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="weibo" href="https://weibo.com/1771030775/" target="_blank">
                        <i class="icon fa fa-weibo"></i>
                    </a>
                </li>
                
            
        </ul>
    </div>
    
        
<nav id="article-nav">
    
    
        <a href="/posts/life/2018-06-12-毕业设计三两事.html" id="article-nav-older" class="article-nav-link-wrap">
        <strong class="article-nav-caption">上一篇</strong>
        <p class="article-nav-title">毕业设计三两事</p>
        <i class="icon fa fa-chevron-left" id="icon-chevron-left"></i>
        </a>
    
</nav>

    
    <div class="widgets-container">
        
            
                
    <div class="widget-wrap">
        <h3 class="widget-title">最新文章</h3>
        <div class="widget">
            <ul id="recent-post" class="">
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/posts/programming/2019-04-04-Spark学习之路（一）.html" class="thumbnail">
    
    
        <span style="background-image:url(https://dylanwen-1256745329.cos.ap-chengdu.myqcloud.com/pic_blog/spark1/spark-logo-trademark.png)" alt="Spark学习之路（一）" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/programming/">滚键盘</a></p>
                            <p class="item-title"><a href="/posts/programming/2019-04-04-Spark学习之路（一）.html" class="title">Spark学习之路（一）</a></p>
                            <p class="item-date"><time datetime="2019-04-04T02:45:49.000Z" itemprop="datePublished">2019-04-04</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/posts/life/2018-06-12-毕业设计三两事.html" class="thumbnail">
    
    
        <span style="background-image:url(https://dylanwen-1256745329.cos.ap-chengdu.myqcloud.com/pic_blog/large.jpg)" alt="毕业设计三两事" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/life/">过日子</a></p>
                            <p class="item-title"><a href="/posts/life/2018-06-12-毕业设计三两事.html" class="title">毕业设计三两事</a></p>
                            <p class="item-date"><time datetime="2018-06-12T10:00:00.000Z" itemprop="datePublished">2018-06-12</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/posts/life/2018-01-16-我的第一篇影评随笔.html" class="thumbnail">
    
    
        <span style="background-image:url(https://dylanwen-1256745329.cos.ap-chengdu.myqcloud.com/pic_blog/wuwenxidong.jpg)" alt="第一篇观影随笔" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/life/">过日子</a></p>
                            <p class="item-title"><a href="/posts/life/2018-01-16-我的第一篇影评随笔.html" class="title">第一篇观影随笔</a></p>
                            <p class="item-date"><time datetime="2018-01-16T02:49:49.000Z" itemprop="datePublished">2018-01-16</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/posts/life/2018-01-09-我的第一篇博文.html" class="thumbnail">
    
    
        <span style="background-image:url(https://i.loli.net/2018/01/11/5a575bb944417.jpg)" alt="我的第一篇博文" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/life/">过日子</a></p>
                            <p class="item-title"><a href="/posts/life/2018-01-09-我的第一篇博文.html" class="title">我的第一篇博文</a></p>
                            <p class="item-date"><time datetime="2018-01-09T15:39:49.000Z" itemprop="datePublished">2018-01-09</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">分类</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/programming/">滚键盘</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/life/">过日子</a><span class="category-list-count">3</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">归档</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/04/">四月 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">六月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">一月 2018</a><span class="archive-list-count">2</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">标签</h3>
        <div class="widget">
            <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Spark/">Spark</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/学习/">学习</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/影评-无问西东-勇敢者游戏2-凶镇谜案/">影评 无问西东 勇敢者游戏2 凶镇谜案</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/生活/">生活</a><span class="tag-list-count">1</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-float">
        <h3 class="widget-title">标签云</h3>
        <div class="widget tagcloud">
            <a href="/tags/Spark/" style="font-size: 10px;">Spark</a> <a href="/tags/学习/" style="font-size: 10px;">学习</a> <a href="/tags/影评-无问西东-勇敢者游戏2-凶镇谜案/" style="font-size: 10px;">影评 无问西东 勇敢者游戏2 凶镇谜案</a> <a href="/tags/生活/" style="font-size: 10px;">生活</a>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">链接</h3>
        <div class="widget">
            <ul>
                
                    <li>
                        <a href="http://hexo.io">Hexo</a>
                    </li>
                
            </ul>
        </div>
    </div>


            
        
    </div>
</aside>
                </div>
            </div>
        </div>
        <footer id="footer">
    <div class="container">
        <div class="container-inner">
            <a id="back-to-top" href="javascript:;"><i class="icon fa fa-angle-up"></i></a>
            <div class="credit">
                <h1 class="logo-wrap">
                    <a href="/" class="logo"></a>
                </h1>
                <p>&copy; 2019 Dylan Wen</p>
                <p>Powered by <a href="//hexo.io/" target="_blank">Hexo</a>. Theme by <a href="//github.com/ppoffice" target="_blank">PPOffice</a></p>
                 <span id="busuanzi_container_site_pv" style="display: inline;">站长统计<span id="busuanzi_value_site_pv"></span>次</span>
            </div>
        </div>
    </div>
</footer>
<script src="//cdn1.lncld.net/static/js/2.5.0/av-min.js"></script>
<script>
    var APP_ID = 'IFjKPoyR4UU8LhN5brVHTX3p-gzGzoHsz';
    var APP_KEY = 'KnztICOY7miwg7QckjXB6E1u';
    AV.init({
        appId: APP_ID,
        appKey: APP_KEY
    });
    // 显示次数
    function showTime(Counter) {
        var query = new AV.Query("Counter");
        if($(".leancloud_visitors").length > 0){
            var url = $(".leancloud_visitors").attr('id').trim();
            // where field
            query.equalTo("words", url);
            // count
            query.count().then(function (number) {
                // There are number instances of MyClass where words equals url.
                $(document.getElementById(url)).text(number?  number : '--');
            }, function (error) {
                // error is an instance of AVError.
            });
        }
    }
    // 追加pv
    function addCount(Counter) {
        var url = $(".leancloud_visitors").length > 0 ? $(".leancloud_visitors").attr('id').trim() : 'icafebolger.com';
        var Counter = AV.Object.extend("Counter");
        var query = new Counter;
        query.save({
            words: url
        }).then(function (object) {
        })
    }
    $(function () {
        var Counter = AV.Object.extend("Counter");
        addCount(Counter);
        showTime(Counter);
    });
    </script>

    <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

        


    
        <script src="/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    
    



<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div>
</body>
</html>
